{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Data Visualization by Example"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "outline\n",
    "    goals\n",
    "        1. well-designed data visualization\n",
    "        2. possibilities of interactive data visualization\n",
    "        3. template of the same\n",
    "    approach\n",
    "        recreate original graph\n",
    "        update for readability (or redesign if necessary)\n",
    "        add interactivity\n",
    "    fundamental issues\n",
    "        Bechdel dimension\n",
    "    1. average bechdel test over time\n",
    "        1.5 trendline of Bechdel test over time \n",
    "    2. makeup of test results over time\n",
    "    3. distribution of budgets by Bechdel dimension\n",
    "    4. profit and ROI by Bechdel dimension\n",
    "        4.5 metascore and IMDB rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Introduction](#Introduction)\n",
    "* [Prologue: Examining the Data](#Prologue:-Examining-The-Data)\n",
    "* [Plot 1: Average Bechdel Score over Time](#Plot-1:-Average-Bechdel-Score-over-Time)\n",
    "    * [Recreating Plot 1](#Recreating-Plot-1)\n",
    "    * [Manipulating Plot 1: Or, The Treachery of Ordinal Data ](#Manipulating-Plot-1:-Or,-The-Treachery-of-Ordinal-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On April 1, 2014, Walt Hickey wrote an article titled [*The Dollar-And-Cents Case Against Hollywoodâ€™s Exclusion of Women*](https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/), which looked at how Hollywood blockbusters have faired in the [Bechdel Test](https://en.wikipedia.org/wiki/Bechdel_test) over the last fifty years. They conclude that films that pass the Bechdel test are not only better representations of gender equality, but also tend to have a higher return on investment (ROI). Because of this, it is in Hollywood's interest to produce films with a more diverse female cast.\n",
    "\n",
    "Several weeks later, on April 21, 2014, Brian Keegan wrote a response titled [*The Need for Openness in Data Journalism*](https://nbviewer.jupyter.org/github/brianckeegan/Bechdel/blob/master/Bechdel_test.ipynb). Using the original article as a case study, Brian point as much about female representation in film (on which he mostly validated Walk Hickey's conclusions, with some caveats) as it is on the importance for making the source code and data for this kind of analysis available. Five Thirty Eight themselves took notice of the response and [linked to it from their site](https://fivethirtyeight.com/features/the-bechdel-test-checking-our-work/), and later made their articles available for replication on their [Github page](https://github.com/fivethirtyeight/data/).\n",
    "\n",
    "This document follows a similar vein; I will use the Bechdel Test data as a worked example of how to create visually appealing plots, and also as a tutorial for creating *interactive* data visualizations. I was spurred to write this document because of a Communication Computational Concepts course I taught at Occidental College in Spring 2018, when I couldn't find good introductions for basic data literacy. My goal here is to not only demonstrate what a good visualization might look like, but also to explain the *thought process* in creating it. Finally, a side effect of writing this document is to illustrate how I use/organize a Jupyter notebook.\n",
    "\n",
    "The overall structure of this document is to take the four main plots in Brian Keegan's document, and for each one:\n",
    "\n",
    "1. recreate the plot with Bokeh\n",
    "2. improve the plot by making it more readable and/or information dense\n",
    "3. create an interactive version that would allow reader exploration\n",
    "\n",
    "Although this document can be viewed statically with the [Jupyter Notebook Viewer](http://nbviewer.jupyter.org/), the interaction visualizations requires a running Jupyter notebook with Python 3. Those interested can check out the [Github repository](https://github.com/justinnhli/blog-code/tree/master/2018/05/bechdel) to run it locally.\n",
    "\n",
    "Note: I am assuming that the reader are passingly fluent with pandas DataFrames (and Python, of course). DataFrame operations will mostly not be explained, but feel free to look up the functions in the [DataFrame API reference](https://pandas.pydata.org/pandas-docs/stable/api.html) as we go along. If you need a refresher on pandas, I recommend working through [First Python Notebook](http://www.firstpythonnotebook.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prologue: Examining The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, ColumnDataSource, show, output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get dive into making pretty graphs, we need to understand the data that we are using to create those graphs. The data I am using here are the same ones that Brian Keegan collected in April 2014. Specifically, he used data from four different sources:\n",
    "\n",
    "* [BechdelTest.com](http://bechdeltest.com/) for how films scored on the Bechdel test\n",
    "* [The-Numbers.com](https://www.the-numbers.com/) for the budget and revenue data\n",
    "* [The Bureau of Labor Statistics](https://www.bls.gov/) for historical inflation data\n",
    "* [The Open Movie Database (OMBD)](https://www.omdbapi.com/) for rating data\n",
    "\n",
    "The following code is copied almost verbatim from Brian Keegan.\n",
    "\n",
    "Two pedagogical notes about this code:\n",
    "\n",
    "1. I tend to write one-off functions that encapsulate most of the processing, then call that function and save the results into a variable. This keeps the main namespace relatively clean.\n",
    "\n",
    "2. I have found that it is a good idea to read the data in one cell, then manipulate copies of it in subsequent cells. This allows for quicker iteration of code, since you don't have to re-read the data if you screw up. This also prevents the `a value is trying to be set on a copy of a slice from a DataFrame` error. What I tend to do is write the code outside a function and test it as I go, then wrap it in a function when I get it working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "\n",
    "    def read_revenues():\n",
    "        return pd.read_csv('data/revenue.csv', encoding='utf8', index_col=0)\n",
    "\n",
    "    def read_inflations():\n",
    "        inflation_df = pd.read_csv('data/cpi.csv', index_col='Year')\n",
    "        inflation_df = inflation_df['Annual']\n",
    "        return dict(inflation_df.loc[2014] / inflation_df)\n",
    "\n",
    "    def read_bechdel():\n",
    "        bechdel_df = pd.read_json('data/bechdel.json')\n",
    "        bechdel_df['imdbid'] = bechdel_df['imdbid'].dropna().apply(int)\n",
    "        bechdel_df = bechdel_df.set_index('imdbid')\n",
    "        bechdel_df.dropna(subset=['title'], inplace=True)\n",
    "        bechdel_df = bechdel_df[['rating', 'title']]\n",
    "        return bechdel_df\n",
    "\n",
    "    def read_imdb():\n",
    "\n",
    "        def runtime_to_minutes(runtime):\n",
    "            if 'h' in runtime:\n",
    "                hours, minutes = runtime.split('h')\n",
    "                return str(int(hours) * 60 + int(minutes))\n",
    "            else:\n",
    "                return runtime\n",
    "\n",
    "        # Read the data in\n",
    "        imdb_df = pd.read_json('data/imdb_data.json')\n",
    "\n",
    "        # Drop non-movies\n",
    "        imdb_df = imdb_df[imdb_df['Type'] == 'movie']\n",
    "\n",
    "        # Drop movies with unknown release dates\n",
    "        imdb_df = imdb_df[imdb_df['Released'] != 'N/A']\n",
    "\n",
    "        # Convert to datetime objects\n",
    "        imdb_df['Released'] = pd.to_datetime(imdb_df['Released'], format=\"%d %b %Y\")\n",
    "\n",
    "        # Drop errant identifying characters in the ID field\n",
    "        imdb_df['imdbID'] = imdb_df['imdbID'].str.slice(start=2)\n",
    "\n",
    "        # Remove the \" min\" at the end of Runtime entries so we can convert to ints\n",
    "        imdb_df['Runtime'] = imdb_df['Runtime'].str.slice(stop=-4).replace('', np.nan)\n",
    "\n",
    "        # Convert errant runtimes to minutes\n",
    "        imdb_df['Runtime'] = imdb_df['Runtime'].astype(str).apply(runtime_to_minutes)\n",
    "\n",
    "        # Blank out non-MPAA or minor ratings (NC-17, X)\n",
    "        imdb_df['Rated'] = imdb_df['Rated'].replace(\n",
    "            to_replace=[\n",
    "                'N/A',\n",
    "                'Not Rated',\n",
    "                'Approved',\n",
    "                'Unrated',\n",
    "                'TV-PG',\n",
    "                'TV-G',\n",
    "                'TV-14',\n",
    "                'TV-MA',\n",
    "                'NC-17',\n",
    "                'X',\n",
    "            ],\n",
    "            value=np.nan,\n",
    "        )\n",
    "\n",
    "        # Convert Release datetime into new columns for year, month, and week\n",
    "        imdb_df['Year'] = imdb_df['Released'].apply(lambda date: date.year)\n",
    "        imdb_df['Month'] = imdb_df['Released'].apply(lambda date: date.month)\n",
    "        imdb_df['Week'] = imdb_df['Released'].apply(lambda date: date.week)\n",
    "\n",
    "        # Convert the series to float\n",
    "        imdb_df['Runtime'] = imdb_df['Runtime'].apply(float)\n",
    "\n",
    "        # Convert the imdbVotes strings into float\n",
    "        imdb_df['imdbVotes'] = imdb_df['imdbVotes'].replace('N/A', np.nan).dropna().apply(\n",
    "            lambda s: float(s.replace(',', ''))\n",
    "        )\n",
    "\n",
    "        # Take the Metascore formatted as string containing \"N/A\", convert to float\n",
    "        # Also divide by 10 to make effect sizes more comparable\n",
    "        imdb_df['Metascore'] = imdb_df['Metascore'].dropna().replace('N/A', np.nan).dropna().apply(float) / 10\n",
    "\n",
    "        # Take the imdbRating formatted as string containing \"N/A\", convert to float\n",
    "        imdb_df['imdbRating'] = imdb_df['imdbRating'].dropna().replace('N/A', np.nan).dropna().apply(float)\n",
    "\n",
    "        # Create a dummy variable for English language\n",
    "        imdb_df['English'] = (imdb_df['Language'] == u'English').astype(int)\n",
    "        imdb_df['USA'] = (imdb_df['Country'] == u'USA').astype(int)\n",
    "\n",
    "        # Convert imdb_ID to int, set it as the index\n",
    "        imdb_df['imdbID'] = imdb_df['imdbID'].dropna().apply(int)\n",
    "        imdb_df = imdb_df.set_index('imdbID')\n",
    "\n",
    "        return imdb_df\n",
    "\n",
    "    def get_combined_data():\n",
    "        revenue_df = read_revenues()\n",
    "        inflation_dict = read_inflations()\n",
    "        bechdel_df = read_bechdel()\n",
    "        imdb_df = read_imdb()\n",
    "        df = imdb_df.join(bechdel_df, how='inner').reset_index()\n",
    "        df = pd.merge(df, revenue_df, left_on=['Title', 'Year'], right_on=['Movie', 'Year'])\n",
    "        df['Year'] = df['Released_x'].apply(lambda date: date.year)\n",
    "        df['Adj_Revenue'] = df.apply(lambda row: row['Revenue'] * inflation_dict[row['Year']], axis=1)\n",
    "        df['Adj_Budget'] = df.apply(lambda row: row['Budget'] * inflation_dict[row['Year']], axis=1)\n",
    "        return df\n",
    "\n",
    "    return get_combined_data()\n",
    "\n",
    "\n",
    "raw_df = read_data()\n",
    "raw_df.tail(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A commonly-overlooked part of creating data visualizations is *understanding the data*. There are at least two things worth noting here:\n",
    "\n",
    "First, since I am using Brian's original 2014 data, all dollar amounts will be in 2014 dollars.\n",
    "\n",
    "Second, and more importantly, it's worth understanding what Brian called the \"Bechdel score\" or the \"Bechdel dimension\". This is the `rating` column (row in the above sample) is the rating from bechdeltest.com. As Brian quoted from their API: \n",
    "\n",
    "> The actual score. Number from 0 to 3.\n",
    "> * 0.0 means no two women,\n",
    "> * 1.0 means no talking, \n",
    "> * 2.0 means talking about a man, \n",
    "> * 3.0 means it passes the test.\n",
    "\n",
    "Note that *the data is **ordinal** and not numeric*. The only semantic information available is that a film with no women is \"worse\" than a film with no women talking, which is in turn worse than a film with women talking about a man. The mapping to 0, 1, 2, and 3 is *arbitrary* - we could just as well map it to -7, 0.5, 0.6, 1000; all that matters is the numbers are increasing. As [Wikipedia page on ordinal data](https://en.wikipedia.org/wiki/Ordinal_data#General) says, \"the use of means and standard deviations ... [is] not appropriate\".\n",
    "\n",
    "This leads directly to Brian's first data plot..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 1: Average Bechdel Score over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brian has a plot that compares the data he collected with that of FiveThirtyEight's. Although we can now get the original data from FiveThirtyEight's repository, we will ignore that plot for the sake of sticking with the information Brian had at the time of his writing.\n",
    "\n",
    "The next plot that Brian presents is the average Bechdel score over time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Original Average Bechdel Test over Time Plot](original-plots/1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that ordinal data stuff from the last section, and how we shouldn't use means and standard deviations? *This plot violates that rule.* As we will see, the average Bechdel score (and so the plot itself) is almost meaningless, and its appearance can be changed drastically with a very different mapping of Bechdel categories to numbers.\n",
    "\n",
    "But first, let's recreate this plot in Bokeh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreating Plot 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes the raw DataFrame from before and extracts only the year and rating information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot_1_data():\n",
    "    \n",
    "    # create a DataFrame that will contiain the data to be plotted\n",
    "    plot_df = raw_df.copy()\n",
    "\n",
    "    # select only the columns we will need\n",
    "    plot_df = plot_df[['Year', 'rating']]\n",
    "\n",
    "    # find the mean rating for each year\n",
    "    plot_df = plot_df.groupby(by='Year').mean()\n",
    "\n",
    "    # reset the index so Bokeh can understand the data\n",
    "    plot_df = plot_df.reset_index()\n",
    "    \n",
    "    return plot_df\n",
    "\n",
    "prepare_plot_1_data().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the data, we will use the [Bokeh](https://bokeh.pydata.org/) library. Although there are a lot of plotting libraries to choose from, including [Matplotlib](https://matplotlib.org/) (which is the library that pandas uses for their [plotting functions](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html)), [Seaborn](https://seaborn.pydata.org/), [Plotly](https://plot.ly/), and more recently [ggplot](http://ggplot.yhathq.com/) and [Altair](https://altair-viz.github.io/), I personally like Bokeh's approach of layering glyphs on top of each other, which makes it easy to add additional visual components. \n",
    "\n",
    "Creating a Bokeh plot involves three steps (after wrangling the data into shape):\n",
    "\n",
    "1. Creating the Figure object. This is simply a call to the [`figure()`](https://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.figure) factory function. Some plot-level attributes such as size, title, axes, etc. can be set at this point.\n",
    "\n",
    "2. Creating glyphs that represent the data. This involves calling at least one of the many glyph methods [in the Figure class](https://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure). Each glyph takes different arguments; a [`circle()` glyph](https://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.circle), for example, takes `x` and `y`, while a [`vbar()` glyph](https://bokeh.pydata.org/en/latest/docs/reference/plotting.html#bokeh.plotting.figure.Figure.vbar) (a vertical rectangle) takes `x`, `width`, `top`, and `bottom`. Central to this API is that each glyph takes a `source` keyword argument, which tells the glyph where to get the data from. Most of the time, if you are using using Bokeh with pandas, this source will be a [ColumnDataSource](https://bokeh.pydata.org/en/latest/docs/reference/models/sources.html#bokeh.models.sources.ColumnDataSource) created from a pandas DataFrame.\n",
    "\n",
    "3. Showing the figure. In a Jupyter notebook, this means two things. First, to tell Bokeh that you are working in a Jupyter notebook, the [`output_notebook()`](https://bokeh.pydata.org/en/latest/docs/reference/io.html#bokeh.io.output_notebook) function must be called. I tend to do this at the start right after I import the necessary libraries. Once we have that, we call the [`show()`](https://bokeh.pydata.org/en/latest/docs/reference/io.html#bokeh.io.show) function for each figure we want to display.\n",
    "\n",
    "We follow these three steps in the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot_1():\n",
    "    \n",
    "    # get the data for the plot\n",
    "    plot_df = prepare_plot_1_data()\n",
    "    \n",
    "    # convert it to a ColumnDataSource\n",
    "    data_source = ColumnDataSource(plot_df)\n",
    "    \n",
    "    # create the figure (step 1)\n",
    "    fig = figure()\n",
    "    \n",
    "    # create the glyph, in this case, a line (step 2)\n",
    "    fig.line(\n",
    "        # use the 'Year' column as the x value\n",
    "        x='Year',\n",
    "        # use the 'rating' column as the y value\n",
    "        y='rating',\n",
    "        # use the converted ColumnDataSource as the source of columns\n",
    "        source=data_source,\n",
    "    )\n",
    "    \n",
    "    # show the plot (step 3)\n",
    "    show(fig)\n",
    "\n",
    "show_plot_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice thing about Bokeh is that the plots are semi-interactive by default - you can drag the plot to pan around, use the tools on the right to zoom in, or reset the plot to the original view.\n",
    "\n",
    "We used the Bokeh defaults for this first attempt, but we can style it a bit more. In the code below, we will change the plot size, set the domain and range, and add axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot_1():\n",
    "    \n",
    "    # get the data for the plot\n",
    "    plot_df = prepare_plot_1_data()\n",
    "    \n",
    "    # convert it to a ColumnDataSource\n",
    "    data_source = ColumnDataSource(plot_df)\n",
    "    \n",
    "    # create the figure (step 1)\n",
    "    fig = figure(\n",
    "        # set the size of the plot\n",
    "        width=600, height=400,\n",
    "        # set the domain and range\n",
    "        x_range=[1910, 2020],\n",
    "        y_range=[0, 3],\n",
    "        # set axis labels\n",
    "        x_axis_label='Year',\n",
    "        y_axis_label='Avg. Bechdel Test',\n",
    "    )\n",
    "    \n",
    "    # create the glyph, in this case, a line (step 2)\n",
    "    fig.line(\n",
    "        # use the 'Year' column as the x value\n",
    "        x='Year',\n",
    "        # use the 'rating' column as the y value\n",
    "        y='rating',\n",
    "        # use the converted ColumnDataSource as the source of columns\n",
    "        source=data_source,\n",
    "    )\n",
    "    \n",
    "    # show the plot (step 3)\n",
    "    show(fig)\n",
    "\n",
    "show_plot_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking back at the original plot, we can see that we've recreated most of the visual elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Original Average Bechdel Test over Time Plot](original-plots/1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one element we *didn't* get is the line width - if you look at the original closely, you will see that the lines gets thicker towards the right. Brian never explains what this means in his text, but if you look at his code, you will see this in cell 37:\n",
    "\n",
    "    lines = LineCollection(lines, linewidths=dict(num_movies).values())\n",
    "\n",
    "It seems like the line width represents how many movies were averaged over. Unfortunately, Bokeh does not offer an easy way to varying the line width. What we have to do instead is draw each line separately by looping over the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_1():\n",
    "    \n",
    "    # prepare the data\n",
    "    plot_df = raw_df.copy()\n",
    "    plot_df = plot_df[['Year', 'rating']]\n",
    "    # calculate the mean and number of ratings separately then combine them\n",
    "    plot_df = pd.concat(\n",
    "        [\n",
    "            plot_df.groupby(by='Year').mean()['rating'],\n",
    "            plot_df.groupby(by='Year').count()['rating'],\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    plot_df = plot_df.reset_index()\n",
    "    # rename the columns appropriately\n",
    "    plot_df.columns = ['Year', 'rating', 'count']\n",
    "    \n",
    "    fig = figure(\n",
    "        width=600, height=400,\n",
    "        x_range=[1910, 2020],\n",
    "        y_range=[0, 3],\n",
    "        x_axis_label='Year',\n",
    "        y_axis_label='Avg. Bechdel Test',\n",
    "    )\n",
    "    \n",
    "    # convert the DataFrame into a list of rows\n",
    "    # take each pair of rows and plot them as a line\n",
    "    rows_list = list(plot_df.itertuples())\n",
    "    for start, end in zip(rows_list[:-1], rows_list[1:]):\n",
    "        fig.line(\n",
    "            x=[start[1], end[1]],\n",
    "            y=[start[2], end[2]],\n",
    "            line_width=start[3],\n",
    "        )\n",
    "        \n",
    "        \n",
    "    show(fig)\n",
    "\n",
    "plot_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is almost there, except that the line on the right side are too thick; however, merely dividing the width by a number makes the other lines too thin. After some experimentation, it turns out using the log of the count gives the appropriate appearance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_1():\n",
    "    \n",
    "    # prepare the data\n",
    "    plot_df = raw_df.copy()\n",
    "    plot_df = plot_df[['Year', 'rating']]\n",
    "    # calculate the mean and number of ratings separately then combine them\n",
    "    plot_df = pd.concat(\n",
    "        [\n",
    "            plot_df.groupby(by='Year').mean()['rating'],\n",
    "            plot_df.groupby(by='Year').count()['rating'],\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    plot_df = plot_df.reset_index()\n",
    "    # rename the columns appropriately\n",
    "    plot_df.columns = ['Year', 'rating', 'count']\n",
    "    \n",
    "    fig = figure(\n",
    "        width=600, height=400,\n",
    "        x_range=[1910, 2020],\n",
    "        y_range=[0, 3],\n",
    "        x_axis_label='Year',\n",
    "        y_axis_label='Avg. Bechdel Test',\n",
    "    )\n",
    "    \n",
    "    rows_list = list(plot_df.itertuples())\n",
    "    for start, end in zip(rows_list[:-1], rows_list[1:]):\n",
    "        fig.line(\n",
    "            x=[start[1], end[1]],\n",
    "            y=[start[2], end[2]],\n",
    "            line_width=math.log(start[3]),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    show(fig)\n",
    "\n",
    "plot_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it: the original Bechdel test over time plot recreated in Bokeh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Plot 1: Or, The Treachery of Ordinal Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ![Original Average Bechdel Test over Time Plot](original-plots/1b.png)\n",
    "        </td>\n",
    "        <td>\n",
    "            ![Original Average Bechdel Test over Time Plot](original-plots/1c.png)\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 2: Bechdel Score Distribution over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](original-plots/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 3: Film Budget by Bechdel Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](original-plots/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 4: Other Metrics by Bechdel Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ![Original Average Bechdel Test over Time Plot](original-plots/4a.png)\n",
    "        </td>\n",
    "        <td>\n",
    "            ![Original Average Bechdel Test over Time Plot](original-plots/4b.png)\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ![Original Average Bechdel Test over Time Plot](original-plots/4c.png)\n",
    "        </td>\n",
    "        <td>\n",
    "            ![Original Average Bechdel Test over Time Plot](original-plots/4d.png)\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
