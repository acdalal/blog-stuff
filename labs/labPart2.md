## Ethical Engine Lab, Part 2

### Before you begin

Please work with your current partner on this lab.

In addition to the files from [Part 1](labPart1.md), you will need this file for today's lab:

[find_difference.py](find_difference.py)

Please download this and save it in the same directory as the rest of your files for this lab.

### Introduction

Today's lab is a continuation of the [Ethical Engine Lab](labPart1.md) from last class. In today's portion of the lab, you will take a closer look at your automatic decision making process and reflect on its implications. 

If you did not finish Step 2 (implementing your automatic decision algorithm) last time, please finish it now before proceeding.

### Step 3

Run and test `automatic.py` once you've finished implementing your automatic decision algorithm. This will apply your function to 60 random scenarios. Make a note of the statistics generated by your algorithm's decisions.

With your partner, answer the following questions:

1.  Consider your manual decision making process.
    *   Are there attributes of the passengers and pedestrians that had a higher (or lower) survival rate, but that was not a conscious factor in your decision process?
    *   What attributes went into your decisions? Does that attribute positively or negatively affect that person’s survival? Why did you consider those attributes?
    *   Is the use of those attributes to make those decision "fair" or "ethical" or "moral"? Why/Why not?
2.  Modify `main()` in `find_difference.py` so that `manual_file` refers to the name of the manual decision file you generated in Part 1 of the lab. Run `find_difference.py`, which will run your function on the same 60 scenarios you manually worked through, and show you the scenarios where your automatic and manual decisions differed. (Note: you will need to scroll up through the terminal to read through all of the output of this program. You might want to copy and paste the output to a text file, so that you can more easily read through it.) Answer the following questions:
    *   How accurately did your automatic model match up with your manual decisions?
    *   For each scenario where your manual and automatic decisions disagreed, explain why. What were you considering when you made the decision manually? What did the automatic decision not take into account, or what did it take into account that it shouldn’t?
3.  Change the last lines of `automatic.py` to run on 100,000 random scenarios. Include these statistics in your submission. Compare the simulated rates of being saved within each attribute (age, gender, etc.). Assign the attribute into one of these categories:

    *   **Category 1:** Deliberately used in decision, and the survival rates reflect what you intended
    *   **Category 2:** Deliberately used in decision, but the survival rates do not reflect what you intended
    *   **Category 3:** Not explicitly used in decision, but the survival rates are not equal between groups
    *   **Category 4:** Not explicitly used in decision, and the survival rates are equal between groups.
    
    For every attribute in Category 3, explain why the survival rates are not equal despite not being used in your decision process.
4.  Working with another pair, explain to each other how you made your automatic decisions and compare your statistics from the previous question.
    *   How do the decision processes differ? What was the reasoning behind each difference?
    *   Did that lead to different statistics, in either ranking or in survival rate?
    *   Which decision process would you prefer to be implemented in a self-driving car? Why?
5.  Based on this exercise, what are some challenges to building (and programming) ethical self-driving cars?

### Submission

Please turn in the following files:

*   `automatic.py`, with `automatic_decision()` implemented.
*   Your manual and automatic **log files**.
*   A **plain text** file with the answers to the questions above.

This lab counts as 10 points towards your Projects grade for the course.
